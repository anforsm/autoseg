{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anton/miniforge3/envs/segmentation/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from autoseg.config import read_config\n",
    "from autoseg.models import Model\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = read_config(\"autoseg/user_configs/anton/baselines/unet_convnext\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 8, 8], [1, 4, 4], [1, 2, 2]]\n"
     ]
    }
   ],
   "source": [
    "model = Model(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (model): ConfigurableUNet(\n",
       "    (unet): UNet(\n",
       "      (l_conv): ModuleList(\n",
       "        (0): ConvNeXtPass(\n",
       "          (passes): ModuleList(\n",
       "            (0): ConvNeXtPassInner(\n",
       "              (conv1): Conv3d(1, 1, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
       "              (norm): LayerNorm((1,), eps=1e-05, elementwise_affine=True)\n",
       "              (conv2): Linear(in_features=1, out_features=24, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (conv3): Linear(in_features=24, out_features=12, bias=True)\n",
       "            )\n",
       "            (1-3): 3 x ConvNeXtPassInner(\n",
       "              (conv1): Conv3d(12, 12, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
       "              (norm): LayerNorm((12,), eps=1e-05, elementwise_affine=True)\n",
       "              (conv2): Linear(in_features=12, out_features=24, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (conv3): Linear(in_features=24, out_features=12, bias=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): ConvNeXtPass(\n",
       "          (passes): ModuleList(\n",
       "            (0): ConvNeXtPassInner(\n",
       "              (conv1): Conv3d(12, 12, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
       "              (norm): LayerNorm((12,), eps=1e-05, elementwise_affine=True)\n",
       "              (conv2): Linear(in_features=12, out_features=72, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (conv3): Linear(in_features=72, out_features=36, bias=True)\n",
       "            )\n",
       "            (1-3): 3 x ConvNeXtPassInner(\n",
       "              (conv1): Conv3d(36, 36, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
       "              (norm): LayerNorm((36,), eps=1e-05, elementwise_affine=True)\n",
       "              (conv2): Linear(in_features=36, out_features=72, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (conv3): Linear(in_features=72, out_features=36, bias=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): ConvNeXtPass(\n",
       "          (passes): ModuleList(\n",
       "            (0): ConvNeXtPassInner(\n",
       "              (conv1): Conv3d(36, 36, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
       "              (norm): LayerNorm((36,), eps=1e-05, elementwise_affine=True)\n",
       "              (conv2): Linear(in_features=36, out_features=216, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (conv3): Linear(in_features=216, out_features=108, bias=True)\n",
       "            )\n",
       "            (1-3): 3 x ConvNeXtPassInner(\n",
       "              (conv1): Conv3d(108, 108, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
       "              (norm): LayerNorm((108,), eps=1e-05, elementwise_affine=True)\n",
       "              (conv2): Linear(in_features=108, out_features=216, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (conv3): Linear(in_features=216, out_features=108, bias=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (3): ConvNeXtPass(\n",
       "          (passes): ModuleList(\n",
       "            (0): ConvNeXtPassInner(\n",
       "              (conv1): Conv3d(108, 108, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
       "              (norm): LayerNorm((108,), eps=1e-05, elementwise_affine=True)\n",
       "              (conv2): Linear(in_features=108, out_features=648, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (conv3): Linear(in_features=648, out_features=324, bias=True)\n",
       "            )\n",
       "            (1-3): 3 x ConvNeXtPassInner(\n",
       "              (conv1): Conv3d(324, 324, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
       "              (norm): LayerNorm((324,), eps=1e-05, elementwise_affine=True)\n",
       "              (conv2): Linear(in_features=324, out_features=648, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (conv3): Linear(in_features=648, out_features=324, bias=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (l_down): ModuleList(\n",
       "        (0-2): 3 x Downsample(\n",
       "          (down): MaxPool3d(kernel_size=(1, 2, 2), stride=(1, 2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "      )\n",
       "      (r_up): ModuleList(\n",
       "        (0): ModuleList(\n",
       "          (0): Upsample(\n",
       "            (up): ConvTranspose3d(36, 12, kernel_size=(1, 2, 2), stride=(1, 2, 2))\n",
       "          )\n",
       "          (1): Upsample(\n",
       "            (up): ConvTranspose3d(108, 36, kernel_size=(1, 2, 2), stride=(1, 2, 2))\n",
       "          )\n",
       "          (2): Upsample(\n",
       "            (up): ConvTranspose3d(324, 108, kernel_size=(1, 2, 2), stride=(1, 2, 2))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (r_conv): ModuleList(\n",
       "        (0): ModuleList(\n",
       "          (0): ConvNeXtPass(\n",
       "            (passes): ModuleList(\n",
       "              (0): ConvNeXtPassInner(\n",
       "                (conv1): Conv3d(24, 24, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
       "                (norm): LayerNorm((24,), eps=1e-05, elementwise_affine=True)\n",
       "                (conv2): Linear(in_features=24, out_features=24, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (conv3): Linear(in_features=24, out_features=12, bias=True)\n",
       "              )\n",
       "              (1-3): 3 x ConvNeXtPassInner(\n",
       "                (conv1): Conv3d(12, 12, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
       "                (norm): LayerNorm((12,), eps=1e-05, elementwise_affine=True)\n",
       "                (conv2): Linear(in_features=12, out_features=24, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (conv3): Linear(in_features=24, out_features=12, bias=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (1): ConvNeXtPass(\n",
       "            (passes): ModuleList(\n",
       "              (0): ConvNeXtPassInner(\n",
       "                (conv1): Conv3d(72, 72, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
       "                (norm): LayerNorm((72,), eps=1e-05, elementwise_affine=True)\n",
       "                (conv2): Linear(in_features=72, out_features=72, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (conv3): Linear(in_features=72, out_features=36, bias=True)\n",
       "              )\n",
       "              (1-3): 3 x ConvNeXtPassInner(\n",
       "                (conv1): Conv3d(36, 36, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
       "                (norm): LayerNorm((36,), eps=1e-05, elementwise_affine=True)\n",
       "                (conv2): Linear(in_features=36, out_features=72, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (conv3): Linear(in_features=72, out_features=36, bias=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (2): ConvNeXtPass(\n",
       "            (passes): ModuleList(\n",
       "              (0): ConvNeXtPassInner(\n",
       "                (conv1): Conv3d(216, 216, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
       "                (norm): LayerNorm((216,), eps=1e-05, elementwise_affine=True)\n",
       "                (conv2): Linear(in_features=216, out_features=216, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (conv3): Linear(in_features=216, out_features=108, bias=True)\n",
       "              )\n",
       "              (1-3): 3 x ConvNeXtPassInner(\n",
       "                (conv1): Conv3d(108, 108, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
       "                (norm): LayerNorm((108,), eps=1e-05, elementwise_affine=True)\n",
       "                (conv2): Linear(in_features=108, out_features=216, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (conv3): Linear(in_features=216, out_features=108, bias=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (heads): ModuleList(\n",
       "      (0): ConvPass(\n",
       "        (layers): ModuleList(\n",
       "          (0): Conv3d(12, 3, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "          (1): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(\"cuda:1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num params: 14,534,817\n"
     ]
    }
   ],
   "source": [
    "print(f\"Num params: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/anton/github/autoseg/src/autoseg/artifacts/UNet_convnext_3x3x3/checkpoints/best/ckpt.pt\n"
     ]
    }
   ],
   "source": [
    "model.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autoseg.datasets import GunpowderZarrDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from autoseg.datasets.utils import multisample_collate as collate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/anton/.cache/autoseg/datasets/SynapseWeb/kh2015/data/apical.zarr.zip labels/s1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/anton/.cache/autoseg/datasets/SynapseWeb/kh2015/data/apical.zarr.zip labels_mask/s1\n",
      "/home/anton/.cache/autoseg/datasets/SynapseWeb/kh2015/data/apical.zarr.zip raw/s1\n",
      "/home/anton/.cache/autoseg/datasets/SynapseWeb/kh2015/data/oblique.zarr.zip labels/s1\n",
      "/home/anton/.cache/autoseg/datasets/SynapseWeb/kh2015/data/oblique.zarr.zip labels_mask/s1\n",
      "/home/anton/.cache/autoseg/datasets/SynapseWeb/kh2015/data/oblique.zarr.zip raw/s1\n",
      "/home/anton/.cache/autoseg/datasets/SynapseWeb/kh2015/data/spine.zarr.zip labels/s1\n",
      "/home/anton/.cache/autoseg/datasets/SynapseWeb/kh2015/data/spine.zarr.zip labels_mask/s1\n",
      "/home/anton/.cache/autoseg/datasets/SynapseWeb/kh2015/data/spine.zarr.zip raw/s1\n"
     ]
    }
   ],
   "source": [
    "dataset = GunpowderZarrDataset(\n",
    "  config=config[\"pipeline\"],\n",
    "  input_image_shape=config[\"model\"][\"input_image_shape\"],\n",
    "  output_image_shape=config[\"model\"][\"output_image_shape\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(\n",
    "    dataset=dataset,\n",
    "    collate_fn=collate,\n",
    "    batch_size=config[\"training\"][\"train_dataloader\"][\"batch_size\"],\n",
    "    pin_memory=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_it = iter(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_image = next(dataloader_it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 76, 304, 304)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_image[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_img = sample_image[0][0][0][24]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m d3_raw_img \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(sample_image[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m16\u001b[39m:\u001b[38;5;241m32\u001b[39m], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m16\u001b[39m\n\u001b[1;32m      2\u001b[0m d3_raw_img\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m----> 3\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241m.\u001b[39mimshow(d3_raw_img, cmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgray\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "d3_raw_img = np.sum(sample_image[0][0][0][16:32], axis=0) / 16\n",
    "d3_raw_img.shape\n",
    "plt.imshow(d3_raw_img, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(raw_img, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = torch.tensor(sample_image[0])\n",
    "raw = raw.to(\"cuda\")\n",
    "raw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "208*208*48/(16*16*16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = model.model.unet.transformer.layer[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_embeddings = model.model.unet.transformer.embeddings.patch_embeddings(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_embeddings.flatten(2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_np(t):\n",
    "  return t.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_embeddings = to_np(patch_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "13*16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch, emb_channel, z\n",
    "plt.imshow(patch_embeddings[0,39,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def patch_to_original_size(patch):\n",
    "  return patch.repeat(16,axis=0).repeat(16,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = cycle([0,1])\n",
    "overlay = np.array([[next(values) for i in range(13)] for j in range(13)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(overlay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.imshow(patch_to_original_size(2*patch_embeddings[0,39,1]) + raw_img,cmap=\"gray\")\n",
    "plt.imshow(patch_to_original_size(overlay) + 12*d3_raw_img,cmap=\"gray\", vmin=d3_raw_img.min()*12, vmax=d3_raw_img.max()*12+1)\n",
    "#plt.imshow(patch_to_original_size(overlay) + 4*raw_img,cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(d3_raw_img[0*16:2*16,10*16:12*16], cmap=\"gray\", vmin=d3_raw_img.min(), vmax=d3_raw_img.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#num_heads * emb_dim\n",
    "12*(768/12)\n",
    "# (507, 768) * (768)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = model.model.unet.transformer.embeddings(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_layer_out = layer.attn(layer.attention_norm(embeddings), return_raw_scores=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_scores = first_layer_out[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_scores = to_np(attn_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_scores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(attn_scores.min(), attn_scores.max(), attn_scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_map_attn = attn_scores[0,s:s+c,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.unflatten(torch.tensor(first_map_attn),dim=1,sizes=(3,13,13)).numpy().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attn_for_patch_i(attn,x,y,z):\n",
    "  i = z*13*13+y*13+x\n",
    "  p_attn = attn_scores[0,s:s+c,i]\n",
    "  return np.transpose(torch.unflatten(torch.tensor(p_attn),dim=1,sizes=(3,13,13)).numpy(), (0, 2, 3, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_for_patch_i(attn_scores, 52).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z=2\n",
    "x=6\n",
    "y=6\n",
    "#print(\"Mean attention\", attn_for_patch_i(attn_scores, x,y,z)[0,:,:,1].mean())\n",
    "plt.imshow(attn_for_patch_i(attn_scores, x,y,z)[0,:,:,1], cmap=\"hot\", vmin=-2,vmax=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = 4\n",
    "xe = 8 \n",
    "ys = 8 \n",
    "ye = 12\n",
    "tot_attn = None\n",
    "ct = 0\n",
    "for x in range(xs,xe+1):\n",
    "  for y in range(ys,ye+1):\n",
    "    ct += 1\n",
    "    if tot_attn is None:\n",
    "      tot_attn = attn_for_patch_i(attn_scores, x,y,1)\n",
    "    else:\n",
    "      tot_attn += attn_for_patch_i(attn_scores, x,y,1)\n",
    "tot_attn /= ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(d3_raw_img[ys*16:ye*16,xs*16:xe*16], cmap=\"gray\", vmin=d3_raw_img.min(), vmax=d3_raw_img.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tot std: 0.08\n",
    "# std only white patch: 0.28\n",
    "# std white/black patch 0.13\n",
    "print(tot_attn.min(), tot_attn.max(), tot_attn.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(tot_attn[0,:,:,1], cmap=\"hot\", vmin=-2,vmax=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "segmentation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
