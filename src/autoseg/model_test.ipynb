{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from autoseg.config import read_config\n",
    "from autoseg.models import Model\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = read_config(\"autoseg/examples/unetr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(config)\n",
    "model.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Num params: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autoseg.datasets import GunpowderZarrDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from autoseg.datasets.utils import multisample_collate as collate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = GunpowderZarrDataset(\n",
    "  config=config[\"pipeline\"],\n",
    "  input_image_shape=config[\"model\"][\"input_image_shape\"],\n",
    "  output_image_shape=config[\"model\"][\"output_image_shape\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(\n",
    "    dataset=dataset,\n",
    "    collate_fn=collate,\n",
    "    batch_size=config[\"training\"][\"train_dataloader\"][\"batch_size\"],\n",
    "    pin_memory=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_it = iter(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_image = next(dataloader_it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_image[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_img = sample_image[0][0][0][24]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d3_raw_img = np.sum(sample_image[0][0][0][16:32], axis=0) / 16\n",
    "d3_raw_img.shape\n",
    "plt.imshow(d3_raw_img, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(raw_img, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = torch.tensor(sample_image[0])\n",
    "raw = raw.to(\"cuda\")\n",
    "raw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "208*208*48/(16*16*16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = model.model.unet.transformer.layer[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_embeddings = model.model.unet.transformer.embeddings.patch_embeddings(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_embeddings.flatten(2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_np(t):\n",
    "  return t.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_embeddings = to_np(patch_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "13*16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch, emb_channel, z\n",
    "plt.imshow(patch_embeddings[0,39,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def patch_to_original_size(patch):\n",
    "  return patch.repeat(16,axis=0).repeat(16,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = cycle([0,1])\n",
    "overlay = np.array([[next(values) for i in range(13)] for j in range(13)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(overlay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.imshow(patch_to_original_size(2*patch_embeddings[0,39,1]) + raw_img,cmap=\"gray\")\n",
    "plt.imshow(patch_to_original_size(overlay) + 12*d3_raw_img,cmap=\"gray\", vmin=d3_raw_img.min()*12, vmax=d3_raw_img.max()*12+1)\n",
    "#plt.imshow(patch_to_original_size(overlay) + 4*raw_img,cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(d3_raw_img[0*16:2*16,10*16:12*16], cmap=\"gray\", vmin=d3_raw_img.min(), vmax=d3_raw_img.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#num_heads * emb_dim\n",
    "12*(768/12)\n",
    "# (507, 768) * (768)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = model.model.unet.transformer.embeddings(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_layer_out = layer.attn(layer.attention_norm(embeddings), return_raw_scores=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_scores = first_layer_out[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_scores = to_np(attn_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_scores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(attn_scores.min(), attn_scores.max(), attn_scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_map_attn = attn_scores[0,s:s+c,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.unflatten(torch.tensor(first_map_attn),dim=1,sizes=(3,13,13)).numpy().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attn_for_patch_i(attn,x,y,z):\n",
    "  i = z*13*13+y*13+x\n",
    "  p_attn = attn_scores[0,s:s+c,i]\n",
    "  return np.transpose(torch.unflatten(torch.tensor(p_attn),dim=1,sizes=(3,13,13)).numpy(), (0, 2, 3, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_for_patch_i(attn_scores, 52).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z=2\n",
    "x=6\n",
    "y=6\n",
    "#print(\"Mean attention\", attn_for_patch_i(attn_scores, x,y,z)[0,:,:,1].mean())\n",
    "plt.imshow(attn_for_patch_i(attn_scores, x,y,z)[0,:,:,1], cmap=\"hot\", vmin=-2,vmax=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = 4\n",
    "xe = 8 \n",
    "ys = 8 \n",
    "ye = 12\n",
    "tot_attn = None\n",
    "ct = 0\n",
    "for x in range(xs,xe+1):\n",
    "  for y in range(ys,ye+1):\n",
    "    ct += 1\n",
    "    if tot_attn is None:\n",
    "      tot_attn = attn_for_patch_i(attn_scores, x,y,1)\n",
    "    else:\n",
    "      tot_attn += attn_for_patch_i(attn_scores, x,y,1)\n",
    "tot_attn /= ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(d3_raw_img[ys*16:ye*16,xs*16:xe*16], cmap=\"gray\", vmin=d3_raw_img.min(), vmax=d3_raw_img.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tot std: 0.08\n",
    "# std only white patch: 0.28\n",
    "# std white/black patch 0.13\n",
    "print(tot_attn.min(), tot_attn.max(), tot_attn.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(tot_attn[0,:,:,1], cmap=\"hot\", vmin=-2,vmax=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "segmentation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
